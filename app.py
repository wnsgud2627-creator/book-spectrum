import streamlit as st
import pandas as pd
import requests
from google import genai
import json
import io
import re
import time
import os

# ==========================================
# 1. ì„¤ì • ë° API ì´ˆê¸°í™”
# ==========================================
# Secrets ì„¤ì • í™•ì¸ í•„ìš” (ALADIN_TTB_KEY, GOOGLE_API_KEY)
ALADIN_TTB_KEY = st.secrets["ALADIN_TTB_KEY"]
GOOGLE_API_KEY = st.secrets["GOOGLE_API_KEY"]
MODEL_ID = 'gemini-1.5-flash'  # ê°€ì¥ íš¨ìœ¨ì ì¸ Flash ëª¨ë¸ ì‚¬ìš©

DEFAULT_KEYWORDS = (
    "ë§ˆìŒ, ìš©ê¸°, í–‰ë³µ, ì‚¬ë‘, ê°ì •, ìì‹ ê°, ì •ì§, ì•½ì†, ë‚˜ëˆ”, ë°°ë ¤, ì„±ì¥, í˜¸ê¸°ì‹¬, "
    "ê°€ì¡±, ì¹œêµ¬, ì´ì›ƒ, ìœ ì¹˜ì›, ì„ ìƒë‹˜, í˜‘ë ¥, ì¸ì‚¬, ì˜ˆì ˆ, í•¨ê»˜, ë„ì›€, "
    "ìŒì‹, ê±´ê°•, ì²­ê²°, í¸ì‹, ì ìê¸°, í™”ì¥ì‹¤, ì•ˆì „, ì˜· ì…ê¸°, ê·œì¹™, ìƒí™œìŠµê´€, "
    "ë™ë¬¼, ê³¤ì¶©, ë°”ë‹¤, ìˆ², ì‹ë¬¼, ê³„ì ˆ, ë‚ ì”¨, ìš°ì£¼, ì§€êµ¬, í™˜ê²½, ê³µë£¡, ê³¼í•™, "
    "ìƒìƒ, ëª¨í—˜, ìƒ‰ê¹”, ì†Œë¦¬, ê·¸ë¦¬ê¸°, ë§Œë“¤ê¸°, ìŒì•…, ë§ˆë²•, ì˜›ì´ì•¼ê¸°, ì „í†µ"
)

@st.cache_resource
def init_gemini_client():
    return genai.Client(api_key=GOOGLE_API_KEY)

client = init_gemini_client()

# ==========================================
# 2. í•µì‹¬ ê¸°ëŠ¥ í•¨ìˆ˜
# ==========================================

def get_book_info_aladin(title, author=""):
    url = "http://www.aladin.co.kr/ttb/api/ItemSearch.aspx"
    # ì œëª©ì—ì„œ ë¶€ì œ ë“± ì œê±°í•˜ì—¬ ê²€ìƒ‰ ì •í™•ë„ í–¥ìƒ
    clean_title = re.sub(r'\(.*?\)|\[.*?\]', '', str(title))
    query = f"{clean_title} {str(author).strip()}"
    params = {
        'ttbkey': ALADIN_TTB_KEY, 'Query': query, 'QueryType': 'Keyword',
        'MaxResults': 1, 'Output': 'js', 'SearchTarget': 'Book',
        'Version': '20131101', 'OptResult': 'Story,fulldescription'
    }
    try:
        response = requests.get(url, params=params, timeout=5)
        data = json.loads(response.text.strip().rstrip(';'))
        if 'item' in data and data['item']:
            item = data['item'][0]
            desc = f"{item.get('description', '')} {item.get('fullDescription', '')} {item.get('story', '')}"
            return {"isbn13": item.get('isbn13', '-'), "desc": re.sub(r'<[^>]*>', ' ', desc)}
    except: pass
    return None

def refine_with_gemini(book_data, title, keyword_pool):
    if not client or not book_data: return None
    prompt = f"""
    ë‹¹ì‹ ì€ 4~7ì„¸ ë„ì„œ ì¶”ì²œ ì‹œìŠ¤í…œì˜ ë¼ë²¨ëŸ¬ì…ë‹ˆë‹¤. '{title}' ì •ë³´ ê¸°ë°˜ìœ¼ë¡œ ì‘ì—…í•˜ì„¸ìš”.
    [ê·œì¹™] 
    1. ì¤„ê±°ë¦¬: ë‹¤ì •í•œ ì„ ìƒë‹˜ ë§íˆ¬, 3ë¬¸ì¥ ë‚´ì™¸, ë§ˆì§€ë§‰ì€ ì§ˆë¬¸ìœ¼ë¡œ ëë‚¼ ê²ƒ.
    2. í‚¤ì›Œë“œ: ì•„ë˜ [í‘œì¤€ ëª©ë¡]ì—ì„œ 3ê°œ í•„ìˆ˜ ì„ íƒ, ë³¸ë¬¸ ì†Œì¬ì—ì„œ 2ê°œ ì„ íƒ (ì´ 5ê°œ).
    [í‘œì¤€ ëª©ë¡]: {keyword_pool}
    ì •ë³´ ì›ë¬¸: {book_data['desc'][:1000]}
    ì‘ë‹µ í˜•ì‹(JSON): {{"summary": "ë‚´ìš©", "keywords": ["k1", "k2", "k3", "k4", "k5"]}}
    """
    try:
        response = client.models.generate_content(model=MODEL_ID, contents=prompt)
        # JSON ë¶€ë¶„ë§Œ ì¶”ì¶œ
        json_text = re.search(r'\{.*\}', response.text, re.DOTALL)
        return json.loads(json_text.group()) if json_text else None
    except Exception: return None

# ==========================================
# 3. ìŠ¤íŠ¸ë¦¼ë¦¿ UI ë° ë©”ì¸ ë¡œì§
# ==========================================
st.set_page_config(page_title="Book Spectrum v3.0", layout="wide")
st.title("ğŸŒˆ ë¶ ìŠ¤í™íŠ¸ëŸ¼ v3.0")

# ì•ˆì „ì¥ì¹˜: í•˜ë£¨ ìµœëŒ€ ë¶„ì„ ê¶Œìˆ˜ ì„¤ì •
DAILY_MAX_LIMIT = 2500  

with st.sidebar:
    st.header("âš™ï¸ ì„¤ì •")
    user_keyword_list = st.text_area("í‘œì¤€ í‚¤ì›Œë“œ ì‚¬ì „ ê´€ë¦¬", value=DEFAULT_KEYWORDS, height=200)
    st.divider()
    uploaded_file = st.file_uploader("ì›ë³¸ ì—‘ì…€ ì—…ë¡œë“œ (ë„ì„œëª…, ì €ì ì»¬ëŸ¼ í•„ìˆ˜)", type=["xlsx"])
    start_btn = st.button("ğŸš€ ë¶„ì„ ì‹œì‘", type="primary", use_container_width=True)

if uploaded_file:
    # 1. ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™” (ë°ì´í„° ë¡œë“œ)
    if 'display_df' not in st.session_state:
        try:
            raw_df = pd.read_excel(uploaded_file)
            # í•„ìˆ˜ ì»¬ëŸ¼ ìƒì„±
            for col in ['ISBN13', 'ì•„ì´ìš© ì¤„ê±°ë¦¬', 'ì¶”ì²œ í‚¤ì›Œë“œ']:
                if col not in raw_df.columns:
                    raw_df[col] = "ëŒ€ê¸° ì¤‘..."
            if 'ê·¸ë¦°ì´' not in raw_df.columns:
                raw_df['ê·¸ë¦°ì´'] = ""
            st.session_state.display_df = raw_df
        except Exception as e:
            st.error(f"ì—‘ì…€ íŒŒì¼ì„ ì½ëŠ” ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}")

    # 2. íƒ­ êµ¬ì„±
    tab1, tab2 = st.tabs(["ğŸ“ ë¶„ì„ í˜„í™©", "ğŸ“Š í‚¤ì›Œë“œ í†µê³„ ë° í•„í„°"])

    with tab1:
        table_placeholder = st.empty()
        
        # ë°ì´í„°ê°€ ë¡œë“œëœ ê²½ìš°ì—ë§Œ í…Œì´ë¸” í‘œì‹œ
        if 'display_df' in st.session_state:
            table_placeholder.dataframe(st.session_state.display_df, use_container_width=True)

            # ë¶„ì„ ì‹¤í–‰ ë¡œì§
            if start_btn:
                progress_bar = st.progress(0)
                analyzed_count = 0  
                
                # ì•ˆì „í•˜ê²Œ iterrows ì‹¤í–‰
                for i, row in st.session_state.display_df.iterrows():
                    # ì´ë¯¸ ë¶„ì„ëœ í–‰ì€ ê±´ë„ˆëœ€
                    if row['ì•„ì´ìš© ì¤„ê±°ë¦¬'] not in ["ëŒ€ê¸° ì¤‘...", "ê²€ìƒ‰ ì‹¤íŒ¨", "ë¶„ì„ ì‹¤íŒ¨"]:
                        continue
                    
                    # ì¼ì¼ í•œë„ ì²´í¬
                    if analyzed_count >= DAILY_MAX_LIMIT:
                        st.error(f"âš ï¸ ì„¤ì •ëœ í•œë„({DAILY_MAX_LIMIT}ê¶Œ)ì— ë„ë‹¬í•˜ì—¬ ë¶„ì„ì„ ì¤‘ë‹¨í•©ë‹ˆë‹¤.")
                        break
                    
                    title = str(row.get('ë„ì„œëª…', '')).strip()
                    author = str(row.get('ì €ì', row.get('ê¸€ì“´ì´', ''))).strip()
                    
                    if not title or title == "nan":
                        continue

                    # ì•Œë¼ë”˜ ê²€ìƒ‰
                    info = get_book_info_aladin(title, author)
                    if info:
                        st.session_state.display_df.at[i, 'ISBN13'] = info.get('isbn13')
                        # Gemini ë¶„ì„
                        refined = refine_with_gemini(info, title, user_keyword_list)
                        if refined:
                            st.session_state.display_df.at[i, 'ì•„ì´ìš© ì¤„ê±°ë¦¬'] = refined.get('summary')
                            st.session_state.display_df.at[i, 'ì¶”ì²œ í‚¤ì›Œë“œ'] = ", ".join(refined.get('keywords', []))
                            analyzed_count += 1
                        else:
                            st.session_state.display_df.at[i, 'ì•„ì´ìš© ì¤„ê±°ë¦¬'] = "ë¶„ì„ ì‹¤íŒ¨"
                    else:
                        st.session_state.display_df.at[i, 'ì•„ì´ìš© ì¤„ê±°ë¦¬'] = "ê²€ìƒ‰ ì‹¤íŒ¨"
                    
                    # ì‹¤ì‹œê°„ UI ì—…ë°ì´íŠ¸
                    table_placeholder.dataframe(st.session_state.display_df, use_container_width=True)
                    progress_bar.progress((i + 1) / len(st.session_state.display_df))
                    time.sleep(0.5) # API ë¶€í•˜ ë°©ì§€ìš© ë¯¸ì„¸ ì§€ì—°

                st.success(f"âœ… ë¶„ì„ ì™„ë£Œ! (ì´ë²ˆ ì„¸ì…˜ì—ì„œ ì´ {analyzed_count}ê¶Œ ë¶„ì„ë¨)")

    with tab2:
        st.subheader("ğŸ“Œ í‚¤ì›Œë“œ ë¶„í¬ ë° ë„ì„œ í•„í„°ë§")
        if 'display_df' in st.session_state:
            # "ëŒ€ê¸° ì¤‘..."ì´ ì•„ë‹Œ ì‹¤ì œ í‚¤ì›Œë“œë§Œ ì¶”ì¶œ
            kw_series = st.session_state.display_df['ì¶”ì²œ í‚¤ì›Œë“œ'].replace("ëŒ€ê¸° ì¤‘...", None).dropna()
            all_keywords = []
            for kw_str in kw_series:
                all_keywords.extend([k.strip() for k in str(kw_str).split(",")])
            
            if all_keywords:
                kw_counts = pd.Series(all_keywords).value_counts().reset_index()
                kw_counts.columns = ['í‚¤ì›Œë“œ', 'ìˆ˜ëŸ‰']
                
                col1, col2 = st.columns([1, 2])
                with col1:
                    selected_keyword = st.selectbox("ì¡°íšŒí•  í‚¤ì›Œë“œ ì„ íƒ", ["ì „ì²´ ë³´ê¸°"] + list(kw_counts['í‚¤ì›Œë“œ']))
                    st.dataframe(kw_counts, use_container_width=True, height=400)
                with col2:
                    st.bar_chart(kw_counts.set_index('í‚¤ì›Œë“œ').head(15))
                
                st.divider()
                st.subheader(f"ğŸ“– '{selected_keyword}' í‚¤ì›Œë“œ í¬í•¨ ë„ì„œ ëª©ë¡")
                if selected_keyword == "ì „ì²´ ë³´ê¸°":
                    st.dataframe(st.session_state.display_df, use_container_width=True)
                else:
                    filtered_df = st.session_state.display_df[
                        st.session_state.display_df['ì¶”ì²œ í‚¤ì›Œë“œ'].str.contains(selected_keyword, na=False, regex=False)
                    ]
                    st.dataframe(filtered_df, use_container_width=True)
            else:
                st.info("ë¶„ì„ì´ ì™„ë£Œë˜ë©´ ì—¬ê¸°ì— í‚¤ì›Œë“œ í†µê³„ê°€ ë‚˜íƒ€ë‚©ë‹ˆë‹¤.")

    # 3. ë‹¤ìš´ë¡œë“œ ë²„íŠ¼ (í•­ìƒ í•˜ë‹¨ì— ë…¸ì¶œ)
    if 'display_df' in st.session_state:
        st.divider()
        output = io.BytesIO()
        with pd.ExcelWriter(output, engine='openpyxl') as writer:
            st.session_state.display_df.to_excel(writer, index=False)
        st.download_button(
            label="ğŸ“¥ ë¶„ì„ ê²°ê³¼ ì—‘ì…€ë¡œ ë‹¤ìš´ë¡œë“œ",
            data=output.getvalue(),
            file_name="Book_Spectrum_Result.xlsx",
            mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
            use_container_width=True
        )
else:
    st.info("ì™¼ìª½ ì‚¬ì´ë“œë°”ì—ì„œ ì—‘ì…€ íŒŒì¼ì„ ì—…ë¡œë“œí•˜ì—¬ ë¶„ì„ì„ ì‹œì‘í•˜ì„¸ìš”.")
