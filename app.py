import streamlit as st
import pandas as pd
import requests
from google import genai
import json
import io
import re
import time
import os

# ==========================================
# 1. ì„¤ì • ë° API ì´ˆê¸°í™”
# ==========================================
ALADIN_TTB_KEY = st.secrets["ALADIN_TTB_KEY"]
GOOGLE_API_KEY = st.secrets["GOOGLE_API_KEY"]
MODEL_ID = 'models/gemini-2.5-flash'

DEFAULT_KEYWORDS = (
    "ë§ˆìŒ, ìš©ê¸°, í–‰ë³µ, ì‚¬ë‘, ê°ì •, ìì‹ ê°, ì •ì§, ì•½ì†, ë‚˜ëˆ”, ë°°ë ¤, ì„±ì¥, í˜¸ê¸°ì‹¬, "
    "ê°€ì¡±, ì¹œêµ¬, ì´ì›ƒ, ìœ ì¹˜ì›, ì„ ìƒë‹˜, í˜‘ë ¥, ì¸ì‚¬, ì˜ˆì ˆ, í•¨ê»˜, ë„ì›€, "
    "ìŒì‹, ê±´ê°•, ì²­ê²°, í¸ì‹, ì ìê¸°, í™”ì¥ì‹¤, ì•ˆì „, ì˜· ì…ê¸°, ê·œì¹™, ìƒí™œìŠµê´€, "
    "ë™ë¬¼, ê³¤ì¶©, ë°”ë‹¤, ìˆ², ì‹ë¬¼, ê³„ì ˆ, ë‚ ì”¨, ìš°ì£¼, ì§€êµ¬, í™˜ê²½, ê³µë£¡, ê³¼í•™, "
    "ìƒìƒ, ëª¨í—˜, ìƒ‰ê¹”, ì†Œë¦¬, ê·¸ë¦¬ê¸°, ë§Œë“¤ê¸°, ìŒì•…, ë§ˆë²•, ì˜›ì´ì•¼ê¸°, ì „í†µ"
)

@st.cache_resource
def init_gemini_client():
    return genai.Client(api_key=GOOGLE_API_KEY)

client = init_gemini_client()

# ==========================================
# 2. í•µì‹¬ ê¸°ëŠ¥ í•¨ìˆ˜
# ==========================================

def get_book_info_aladin(title, author=""):
    url = "http://www.aladin.co.kr/ttb/api/ItemSearch.aspx"
    clean_title = re.sub(r'\(.*?\)|\[.*?\]', '', str(title))
    query = f"{clean_title} {str(author).strip()}"
    params = {
        'ttbkey': ALADIN_TTB_KEY, 'Query': query, 'QueryType': 'Keyword',
        'MaxResults': 1, 'Output': 'js', 'SearchTarget': 'Book',
        'Version': '20131101', 'OptResult': 'Story,fulldescription'
    }
    try:
        response = requests.get(url, params=params, timeout=5)
        data = json.loads(response.text.strip().rstrip(';'))
        if 'item' in data and data['item']:
            item = data['item'][0]
            desc = f"{item.get('description', '')} {item.get('fullDescription', '')} {item.get('story', '')}"
            return {"isbn13": item.get('isbn13', '-'), "desc": re.sub(r'<[^>]*>', ' ', desc)}
    except: pass
    return None

def refine_with_gemini(book_data, title, keyword_pool):
    if not client or not book_data: return None
    prompt = f"""
    ë‹¹ì‹ ì€ 4~7ì„¸ ë„ì„œ ì¶”ì²œ ì‹œìŠ¤í…œì˜ ì „ë¬¸ ì¹´í”¼ë¼ì´í„°ì…ë‹ˆë‹¤. 
    ì œê³µëœ '{title}'ì˜ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ, ì•„ì´ì™€ ë¶€ëª¨ê°€ í•¨ê»˜ ì½ê³  ì‹¶ë„ë¡ ì¤„ê±°ë¦¬ë¥¼ ì¬êµ¬ì„±í•˜ì„¸ìš”.

    [ì‘ì„± ê·œì¹™]
    1. **ì ˆëŒ€ ê¸ˆì§€**: "ì¹œêµ¬ë“¤", "ì•ˆë…•", "ì†Œê°œí• ê²Œìš”", "ì´ ì±…ì€"ìœ¼ë¡œ ì‹œì‘í•˜ëŠ” ìƒíˆ¬ì ì¸ ë¬¸êµ¬ëŠ” ì‚­ì œí•˜ì„¸ìš”.
    2. **ì²« ë¬¸ì¥**: ì±…ì˜ êµ¬ì²´ì ì¸ ë°°ê²½ì´ë‚˜ ë“±ì¥ì¸ë¬¼(ì˜ˆ: ë¹¨ê°„ ì½”ë¼ë¦¬, ê°œë¯¸, í˜¸ë‘ì´ ë“±)ë¡œ ì¦‰ì‹œ ì‹œì‘í•˜ì„¸ìš”.
    3. **í†¤ì•¤ë§¤ë„ˆ**: ë‹¤ì •í•˜ê³  ë”°ëœ»í•œ ì„¤ëª…ì¡°ë¡œ ì‘ì„±í•˜ë˜, ì§€ë‚˜ì¹œ í™ë³´ì„± ê°íƒ„ì‚¬(!)ëŠ” ì¤„ì´ì„¸ìš”.
    4. **ë‚´ìš©**: ë‹¨ìˆœ ìš”ì•½ì´ ì•„ë‹ˆë¼, ì´ ì±…ì„ ì½ìœ¼ë©´ ì–´ë–¤ ì¦ê±°ì›€ì´ë‚˜ ê°€ì¹˜(ë°°ë ¤, ìˆ«ì ë†€ì´ ë“±)ë¥¼ ëŠë‚„ ìˆ˜ ìˆëŠ”ì§€ ìì—°ìŠ¤ëŸ½ê²Œ í¬í•¨í•˜ì„¸ìš”.
    5. **ë§ˆë¬´ë¦¬**: ì•„ì´ì™€ í•¨ê»˜ í•´ë³¼ ìˆ˜ ìˆëŠ” í™œë™ì´ë‚˜ ëŠê»´ë³¼ ìˆ˜ ìˆëŠ” ê°ì •ì„ ì œì•ˆí•˜ë©° ëë‚´ì„¸ìš”.

    ì •ë³´ ì›ë¬¸: {book_data['desc'][:1000]}
    ì‘ë‹µ í˜•ì‹(JSON): {{"summary": "ë‚´ìš©", "keywords": ["k1", "k2", "k3", "k4", "k5"]}}
    """
    try:
        response = client.models.generate_content(model=MODEL_ID, contents=prompt)
        json_text = re.search(r'\{.*\}', response.text, re.DOTALL)
        return json.loads(json_text.group()) if json_text else None
    except Exception: return None

# ==========================================
# 3. ìŠ¤íŠ¸ë¦¼ë¦¿ UI
# ==========================================
st.set_page_config(page_title="Book Spectrum v3.0", layout="wide")
st.title("ğŸŒˆ ë¶ ìŠ¤í™íŠ¸ëŸ¼ v3.0")

with st.sidebar:
    st.header("âš™ï¸ ì„¤ì •")
    user_keyword_list = st.text_area("í‘œì¤€ í‚¤ì›Œë“œ ì‚¬ì „ ê´€ë¦¬", value=DEFAULT_KEYWORDS, height=200)
    st.divider()
    uploaded_file = st.file_uploader("ì›ë³¸ ì—‘ì…€ ì—…ë¡œë“œ", type=["xlsx"])
    start_btn = st.button("ğŸš€ ë¶„ì„ ì‹œì‘", type="primary", use_container_width=True)

if uploaded_file:
    if 'display_df' not in st.session_state:
        raw_df = pd.read_excel(uploaded_file)
        for col in ['ISBN13', 'ì•„ì´ìš© ì¤„ê±°ë¦¬', 'ì¶”ì²œ í‚¤ì›Œë“œ']:
            if col not in raw_df.columns: raw_df[col] = "ëŒ€ê¸° ì¤‘..."
        if 'ê·¸ë¦°ì´' not in raw_df.columns: raw_df['ê·¸ë¦°ì´'] = ""
        st.session_state.display_df = raw_df

    tab1, tab2 = st.tabs(["ğŸ“ ë¶„ì„ í˜„í™©", "ğŸ“Š í‚¤ì›Œë“œ í†µê³„ ë° í•„í„°"])

    with tab1:
        table_placeholder = st.empty()
        table_placeholder.dataframe(st.session_state.display_df, use_container_width=True)

        if start_btn:
            progress_bar = st.progress(0)
            for i, row in st.session_state.display_df.iterrows():
                if row['ì•„ì´ìš© ì¤„ê±°ë¦¬'] not in ["ëŒ€ê¸° ì¤‘...", "ê²€ìƒ‰ ì‹¤íŒ¨", "ë¶„ì„ ì‹¤íŒ¨"]: continue

                title = str(row.get('ë„ì„œëª…', '')).strip()
                author = str(row.get('ì €ì', row.get('ê¸€ì“´ì´', ''))).strip()
                info = get_book_info_aladin(title, author)

                if info:
                    st.session_state.display_df.at[i, 'ISBN13'] = info.get('isbn13')
                    refined = refine_with_gemini(info, title, user_keyword_list)
                    if refined:
                        st.session_state.display_df.at[i, 'ì•„ì´ìš© ì¤„ê±°ë¦¬'] = refined.get('summary')
                        st.session_state.display_df.at[i, 'ì¶”ì²œ í‚¤ì›Œë“œ'] = ", ".join(refined.get('keywords', []))
                    else: st.session_state.display_df.at[i, 'ì•„ì´ìš© ì¤„ê±°ë¦¬'] = "ë¶„ì„ ì‹¤íŒ¨"
                else: st.session_state.display_df.at[i, 'ì•„ì´ìš© ì¤„ê±°ë¦¬'] = "ê²€ìƒ‰ ì‹¤íŒ¨"

                table_placeholder.dataframe(st.session_state.display_df, use_container_width=True)
                progress_bar.progress((i + 1) / len(st.session_state.display_df))
                time.sleep(1)
            st.success("âœ… ë¶„ì„ ì™„ë£Œ!")

    with tab2:
        st.subheader("ğŸ“Œ í‚¤ì›Œë“œ ë¶„í¬ ë° ë„ì„œ í•„í„°ë§")
        kw_series = st.session_state.display_df['ì¶”ì²œ í‚¤ì›Œë“œ'].dropna()
        all_keywords = []
        for kw_str in kw_series:
            if kw_str != "ëŒ€ê¸° ì¤‘...":
                all_keywords.extend([k.strip() for k in kw_str.split(",")])

        if all_keywords:
            kw_counts = pd.Series(all_keywords).value_counts().reset_index()
            kw_counts.columns = ['í‚¤ì›Œë“œ', 'ìˆ˜ëŸ‰']

            col1, col2 = st.columns([1, 2])
            with col1:
                st.write("âœ… í‚¤ì›Œë“œ ë¦¬ìŠ¤íŠ¸ (í•„í„°ë§í•  í‚¤ì›Œë“œë¥¼ ì„ íƒí•˜ì„¸ìš”)")
                # í‚¤ì›Œë“œ ì„ íƒìš© ì…€ë ‰íŠ¸ë°•ìŠ¤ ì¶”ê°€
                selected_keyword = st.selectbox("ì¡°íšŒí•  í‚¤ì›Œë“œ ì„ íƒ", ["ì „ì²´ ë³´ê¸°"] + list(kw_counts['í‚¤ì›Œë“œ']))
                st.dataframe(kw_counts, use_container_width=True, height=300)

            with col2:
                st.write("ğŸ“ˆ í‚¤ì›Œë“œ ë¶„í¬ ì°¨íŠ¸")
                st.bar_chart(kw_counts.set_index('í‚¤ì›Œë“œ').head(15))

            st.divider()

            # í•„í„°ë§ ê²°ê³¼ ì¶œë ¥
            st.subheader(f"ğŸ“– '{selected_keyword}' í‚¤ì›Œë“œ í¬í•¨ ë„ì„œ ëª©ë¡")
            if selected_keyword == "ì „ì²´ ë³´ê¸°":
                st.dataframe(st.session_state.display_df, use_container_width=True)
            else:
                filtered_df = st.session_state.display_df[
                    st.session_state.display_df['ì¶”ì²œ í‚¤ì›Œë“œ'].str.contains(selected_keyword, na=False)
                ]
                st.dataframe(filtered_df, use_container_width=True)
        else:
            st.info("ë¶„ì„ì´ ì™„ë£Œë˜ë©´ í‚¤ì›Œë“œ í†µê³„ì™€ í•„í„°ë§ ê¸°ëŠ¥ì´ í™œì„±í™”ë©ë‹ˆë‹¤.")

    # ë‹¤ìš´ë¡œë“œ ë²„íŠ¼
    output = io.BytesIO()
    with pd.ExcelWriter(output, engine='openpyxl') as writer:
        st.session_state.display_df.to_excel(writer, index=False)
    st.download_button("ğŸ“¥ ìµœì¢… ê²°ê³¼ ì—‘ì…€ ë‹¤ìš´ë¡œë“œ", data=output.getvalue(), file_name="Book_Spectrum_Final.xlsx", use_container_width=True)
